<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>MultiMT: Multi-modal Context Modelling for Machine Translation</title>
  <meta name="description" content="Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
">

  <link rel="stylesheet" href="/css/normalize.css">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://multimt.github.io/">
  <link rel="alternate" type="application/rss+xml" title="MultiMT: Multi-modal Context Modelling for Machine Translation" href="http://multimt.github.io/feed.xml">
  <link rel="icon" href="images/icon/multimt_favico_16x16.png" type="image/png"> 
  <link rel="icon" href="images/icon/multimt_favico_32x32.png" type="image/png" sizes="32x32"> 
  <link rel="icon" href="images/icon/multimt_favico_64x64.png" type="image/png" sizes="64x64"> 
</head>


  <body>
    <div id="container">
    <header class="site-header">
  <h1><img src="images/logo/multimt_logo.png" alt="MultiMT" title="MultiMT" /></h1>
  <h2>Multi-modal Context Modelling for Machine Translation</h2>

  <blockquote>How do you use images, speech, metadata, etc. to improve machine translation and other applications </blockquote>
</header>


    <main id="page-container">
      <div id="page-content">
        <section id="about">
    <h2><span>About</span></h2>
    
    <p>MultiMT is a project led by <a href="http://staffwww.dcs.shef.ac.uk/people/L.Specia/">Prof. Lucia Specia</a> on her ERC (European Research Council) Starting Grant. The aim of the project is to devise data, methods and algorithms to exploit multi-modal information (images, speech, metadata etc.) for context modelling in Machine Translation. The project is highly interdisciplinary, drawing upon different research fields as such NLP, Computer Vision, Speech Processing and Machine Learning.</p>

    
</section>


<section id="news">
    <h2><span>News</span></h2>

<p class="news-item"><span class="news-item-date">[08/07/2017]</span> <span class="news-item-text">Our system paper for the <a href="http://www.statmt.org/wmt17/multimodal-task.html">WMT Multimodal Machine Translation Shared Task</a> is available.
</span></p>

<p class="news-item"><span class="news-item-date">[16/06/2017]</span> <span class="news-item-text">A paper on fine-tuning with auxiliary data accepted at <a href="http://www.interspeech2017.org/">Interspeech 2017</a>!
</span></p>

<p class="news-item"><span class="news-item-date">[20/05/2017]</span> <span class="news-item-text">A paper on investigating the contribution of image captioning for MMT accepted at <a href="https://ufal.mff.cuni.cz/eamt2017/">EAMT</a>!
</span></p>

</section>


<section id="people">
  <h2><span>Team</span></h2>

  <h3>Members</h3>
  
  <div class="member">
    <a href="http://staffwww.dcs.shef.ac.uk/people/L.Specia/" class="member-picture-link"><img src="images/people/lucia.jpg" /></a><br/>
    <p class="member-name"><a href="http://staffwww.dcs.shef.ac.uk/people/L.Specia/" class="member-name-link">Lucia Specia</a></p>
    <p class="member-role">Leader</p>
    <p class="member-area">(Machine Translation)</p>
  </div>
  
  <div class="member">
    <a href="http://www.cs.upc.edu/~pranava/" class="member-picture-link"><img src="images/people/pranava.jpg" /></a><br/>
    <p class="member-name"><a href="http://www.cs.upc.edu/~pranava/" class="member-name-link">Pranava Madhyastha</a></p>
    <p class="member-role">Postdoctoral researcher</p>
    <p class="member-area">(Machine Learning/NLP)</p>
  </div>
  
  <div class="member">
    <a href="http://www.josiahwang.com/" class="member-picture-link"><img src="images/people/josiah.jpg" /></a><br/>
    <p class="member-name"><a href="http://www.josiahwang.com/" class="member-name-link">Josiah Wang</a></p>
    <p class="member-role">Postdoctoral researcher</p>
    <p class="member-area">(Computer Vision/NLP)</p>
  </div>
  
  <div class="member">
    <a href="https://sites.google.com/site/salildeena/" class="member-picture-link"><img src="images/people/salil.png" /></a><br/>
    <p class="member-name"><a href="https://sites.google.com/site/salildeena/" class="member-name-link">Salil Deena</a></p>
    <p class="member-role">Postdoctoral researcher</p>
    <p class="member-area">(Speech Processing)</p>
  </div>
  
  <div class="member">
    <a href="http://www.dcs.shef.ac.uk/cgi-bin/makeperson?C.Lala" class="member-picture-link"><img src="images/people/chiraag.jpg" /></a><br/>
    <p class="member-name"><a href="http://www.dcs.shef.ac.uk/cgi-bin/makeperson?C.Lala" class="member-name-link">Chiraag Lala</a></p>
    <p class="member-role">Ph.D. postgraduate</p>
    <p class="member-area">&nbsp;</p>
  </div>
  
  <div class="member">
    <a href="#" class="member-picture-link"><img src=" images/people/default.png" /></a><br/>
    <p class="member-name"><a href="#" class="member-name-link">Abigail Smith</a></p>
    <p class="member-role">Research Intern</p>
    <p class="member-area">&nbsp;</p>
  </div>
  

  <h3>Former Members</h3>
  
  <div class="member">
    <a href="http://staffwww.dcs.shef.ac.uk/people/W.Ng/" class="member-picture-link"><img src="images/people/raymond.jpg" /></a><br/>
    <p class="member-name"><a href="http://staffwww.dcs.shef.ac.uk/people/W.Ng/" class="member-name-link">Raymond Ng</a></p>
    <p class="member-role">Postdoctoral researcher</p>
    <p class="member-area">(Speech Processing)</p>
  </div>
  
</section>


<section id="publications">
  <h2><span>Publications</span></h2>

  
  <div class="paper-entry">
      <div class="paper-thumb">
        <div class="paper-thumb-wrapper">
          
          <img src="images/publication_thumb/wmt2017.png" />
          
        </div>
      </div>
      <div class="paper-details">
          
          <p class="paper-title"><a href="http://www.statmt.org/wmt17/pdf/WMT52.pdf">Sheffield MultiMT: Using Object Posterior Predictions for Multimodal Machine Translation</a></p>
          <p class="paper-authors">Pranava Madhyastha*, Josiah Wang*, Lucia Specia (* denotes equal contribution)</p>
          <p class="paper-location">Conference on Machine Translation (WMT), 2017</p>
          <p class="paper-abstract">We participated in the Multimodal Machine Translation (MMT) shared task of translating image descriptions from English to German/French given the corresponding image. Can the use of object posterior predictions instead of lower-level image features help MMT?</p>
          <p class="paper-assets">
          
          <span class="assets-item"><a href="http://www.statmt.org/wmt17/pdf/WMT52.pdf"> <img src="images/icon/pdf.png" class="assets-icon" /><span>Paper</span></a></span>
          
          </p>
      </div>
  </div>
  
  <div class="paper-entry">
      <div class="paper-thumb">
        <div class="paper-thumb-wrapper">
          
          <img src="images/publication_thumb/interspeech2017.png" />
          
        </div>
      </div>
      <div class="paper-details">
          
          <p class="paper-title"><a href="downloads/papers/interspeech2017.pdf">Semi-supervised Adaptation of RNNLMs by Fine-tuning with Domain-specific Auxiliary Features</a></p>
          <p class="paper-authors">Salil Deena, Raymond Ng, Pranava Madhyastha, Lucia Specia, Thomas Hain</p>
          <p class="paper-location">Interspeech, 2017</p>
          <p class="paper-abstract">How do we fine-tune RNN Language Models with auxiliary features for a specific domain?</p>
          <p class="paper-assets">
          
          <span class="assets-item"><a href="downloads/papers/interspeech2017.pdf"> <img src="images/icon/pdf.png" class="assets-icon" /><span>Paper</span></a></span>
          
          </p>
      </div>
  </div>
  
  <div class="paper-entry">
      <div class="paper-thumb">
        <div class="paper-thumb-wrapper">
          
          <img src="images/publication_thumb/eamt2017.png" />
          
        </div>
      </div>
      <div class="paper-details">
          
          <p class="paper-title"><a href="https://ufal.mff.cuni.cz/pbml/108/art-lala-madhyastha-wang-specia.pdf">Unraveling the Contribution of Image Captioning and Neural Machine Translation for Multimodal Machine Translation</a></p>
          <p class="paper-authors">Chiraag Lala, Pranava Madhyastha, Josiah Wang, Lucia Specia</p>
          <p class="paper-location">European Association for Machine Translation (EAMT), 2017</p>
          <p class="paper-abstract">What are the contributions of image captioning and neural machine translation systems in Multimodal Machine Translation? Can we use the output of image captioning systems to rerank neural machine translation hypotheses?</p>
          <p class="paper-assets">
          
          <span class="assets-item"><a href="https://ufal.mff.cuni.cz/pbml/108/art-lala-madhyastha-wang-specia.pdf"> <img src="images/icon/pdf.png" class="assets-icon" /><span>Paper</span></a></span>
          
          <span class="assets-item"><a href="http://www.josiahwang.com/publications/eamt17_poster.pdf"> <img src="images/icon/ppt.png" class="assets-icon" /><span>Poster</span></a></span>
          
          </p>
      </div>
  </div>
  

</section>


<section id="contact">
    <h2><span>Contact</span></h2>
    
    <p>For project/collaboration related queries, please contact <a href="http://staffwww.dcs.shef.ac.uk/people/L.Specia/">Prof. Lucia Specia</a>.</p>

<p>For website related issues please contact <a href="http://www.josiahwang.com/">Josiah Wang</a>.</p>

    
</section>


      </div>
    </div>

    <footer id="site-footer">
  <div id="footer-container">
    <p>MultiMT is funded by the European Union's Horizon 2020 European Research Council (ERC) Starting Grant for Lucia Specia,  under grant agreement No. 678017.</p>
  </div>
</footer>


  <script src="js/jquery-2.2.4.min.js"></script>
  <script src="js/jquery.scrollNav.min.js"></script>

  <script>
$('#page-container').scrollNav({
    showTopLink: false,
    insertLocation: 'appendTo',
    headlineText: ''
});
  </script>

    </div>
  </body>

</html>
